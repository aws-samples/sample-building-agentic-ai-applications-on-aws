{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fact Check Assistant: Deploy Strands Agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -q -r ../src/frontend/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Configure Logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import sys\n",
    "from strands.tools.mcp import MCPClient\n",
    "from mcp import stdio_client, StdioServerParameters\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your .env file\n",
    "env_path = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"src\", \"frontend\", \".env\"))\n",
    "\n",
    "# Load the environment variables from the specified file\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write Agent for Mathematical Calculations to Frontend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/frontend/math_assistant.py\n",
    "\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator\n",
    "\n",
    "MATH_ASSISTANT_SYSTEM_PROMPT = \"\"\"\n",
    "You are math wizard, a specialized mathematics applying mathematics across a wide variety of domains.\n",
    "\n",
    "People need your opinion on the validity of statements they pass to you. Use the tools at your disposal to logically break down a statement to determine whether the statement is true or false. \n",
    "\n",
    "Check the statement for mathematical and process errors.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Mathematical Operations:\n",
    "   - Arithmetic calculations\n",
    "   - Algebraic problem-solving\n",
    "   - Geometric analysis\n",
    "   - Statistical computations\n",
    "\n",
    "2. Teaching Tools:\n",
    "   - Step-by-step problem solving\n",
    "   - Visual explanation creation\n",
    "   - Formula application guidance\n",
    "   - Concept breakdown\n",
    "\n",
    "3. Educational Approach:\n",
    "   - Show detailed work\n",
    "   - Explain mathematical reasoning\n",
    "   - Provide alternative solutions\n",
    "   - Link concepts to real-world applications\n",
    "\n",
    "4. Australian Taxation Rules\n",
    "   - Detailed knowledge of Australian Taxation Office Rules (https://www.ato.gov.au/)\n",
    "   - Ability to perform income tax calculations\n",
    "   - Ability to perform capital gains tax calculations\n",
    "   - Analyse structure of personal finances to minimise tax\n",
    "\n",
    "5. Mortgage Calculations\n",
    "   - Detailed understanding of how mortgages work in Australia\n",
    "\n",
    "Focus on clarity and systematic problem-solving while ensuring people understand the underlying concepts.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def math_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Process and respond to math-related queries using a specialized math agent.\n",
    "\n",
    "    Args:\n",
    "        query: A mathematical question or problem from the user\n",
    "\n",
    "    Returns:\n",
    "        A detailed mathematical answer with explanations and steps\n",
    "    \"\"\"\n",
    "    # Format the query for the math agent with clear instructions\n",
    "    formatted_query = f\"Please solve the following mathematical problem, showing all steps and explaining concepts clearly: {query}\"\n",
    "\n",
    "    try:\n",
    "        # Create the math agent with calculator capability\n",
    "        math_agent = Agent(\n",
    "            model=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "            tools=[calculator],\n",
    "            system_prompt=MATH_ASSISTANT_SYSTEM_PROMPT,\n",
    "        )\n",
    "\n",
    "        agent_response = math_agent(formatted_query)\n",
    "        text_response = str(agent_response)\n",
    "\n",
    "        if len(text_response) > 0:\n",
    "            return text_response\n",
    "\n",
    "        return \"I apologize, but I couldn't solve this mathematical problem. Please check if your query is clearly stated or try rephrasing it.\"\n",
    "    except Exception as e:\n",
    "        # Return specific error message for math processing\n",
    "        return f\"Error processing your mathematical query: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write Agent for Researching Erroneous Claims to Frontend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile  ../src/frontend/research_assistant.py\n",
    "\n",
    "from mcp import StdioServerParameters, stdio_client\n",
    "from strands import Agent, tool\n",
    "from strands.tools.mcp import MCPClient\n",
    "\n",
    "RESEARCH_ASSISTANT_SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant specialized in identifying erroneous or misleading claims in text.\n",
    "\n",
    "Instructions:\n",
    "- Break down the input text into separate statements.\n",
    "- For each statement, determine if it contains misinformation, disinformation, or is otherwise clearly false or misleading.\n",
    "- Fact-check statements using general knowledge and logical reasoning. Look for fabrication, manipulation, or critical omissions.\n",
    "\n",
    "Output:\n",
    "- Return a numbered list of all statements you identify as erroneous, incorrect, or misleading.\n",
    "- Each listed item should be the erroneous claim as a direct quotation.\n",
    "- If there are no erroneous statements, return 'No erroneous claims found.'\n",
    "- Do not return any explanations, extra text, or formatting.\n",
    "\n",
    "Example 1\n",
    "Input:\n",
    "Climate change is a hoax invented by scientists. The Great Wall of China is visible from space.\n",
    "\n",
    "Output:\n",
    "1. \"Climate change is a hoax invented by scientists.\"\n",
    "2. \"The Great Wall of China is visible from space.\"\n",
    "\n",
    "Example 2\n",
    "Input:\n",
    "The Pacific Ocean is the largest ocean on Earth. Drinking bleach can cure illnesses.\n",
    "\n",
    "Output:\n",
    "1. \"Drinking bleach can cure illnesses.\"\n",
    "\n",
    "Example 3\n",
    "Input:\n",
    "\n",
    "Output:\n",
    "No erroneous claims found.\n",
    "\"\"\"\n",
    "\n",
    "stdio_mcp_client = MCPClient(\n",
    "    lambda: stdio_client(\n",
    "        StdioServerParameters(\n",
    "            command=\"uvx\",\n",
    "            args=[\"duckduckgo-mcp-server\"],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "@tool\n",
    "def research_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Fact-check a statement and return whether it's true or false with supporting context.\n",
    "\n",
    "    Args:\n",
    "        statement: The statement or claim to fact-check\n",
    "\n",
    "    Returns:\n",
    "        A fact-check assessment with verdict (TRUE/FALSE/PARTIALLY TRUE) and supporting evidence\n",
    "    \"\"\"\n",
    "    formatted_query = f\"Please fact-check this statement and provide a clear verdict (TRUE/FALSE/PARTIALLY TRUE) with supporting evidence and context: {query}\"\n",
    "\n",
    "    try:\n",
    "        print(\"Routed to Fact Checker\")\n",
    "        with stdio_mcp_client:\n",
    "            # Get the tools from the MCP server\n",
    "            tools = stdio_mcp_client.list_tools_sync()\n",
    "\n",
    "            # Create an agent with MCP tools and fact-checking prompt\n",
    "            fact_checker_agent = Agent(\n",
    "                model=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "                tools=tools,\n",
    "                system_prompt=RESEARCH_ASSISTANT_SYSTEM_PROMPT,\n",
    "            )\n",
    "            agent_response = fact_checker_agent(formatted_query)\n",
    "            text_response = str(agent_response)\n",
    "\n",
    "            if len(text_response) > 0:\n",
    "                return text_response\n",
    "\n",
    "            return \"I apologize, but I couldn't fact-check this statement. Please provide a clear, specific claim to verify.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error during fact-checking: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write Agent for Detecting Erroneous Claims to Frontend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/frontend/claim_detection_assistant.py\n",
    "\n",
    "from strands import Agent, tool\n",
    "\n",
    "CLAIM_DETECTION_ASSISTANT_SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant specialized in identifying erroneous or misleading claims in text.\n",
    "\n",
    "Instructions:\n",
    "- Break down the input text into separate statements.\n",
    "- For each statement, determine if it contains misinformation, disinformation, or is otherwise clearly false or misleading.\n",
    "- Fact-check statements using general knowledge and logical reasoning. Look for fabrication, manipulation, or critical omissions.\n",
    "\n",
    "Output:\n",
    "- Return a numbered list of all statements you identify as erroneous, incorrect, or misleading.\n",
    "- Each listed item should be the erroneous claim as a direct quotation.\n",
    "- If there are no erroneous statements, return 'No erroneous claims found.'\n",
    "- Do not return any explanations, extra text, or formatting.\n",
    "\n",
    "Example 1\n",
    "Input:\n",
    "Climate change is a hoax invented by scientists. The Great Wall of China is visible from space.\n",
    "\n",
    "Output:\n",
    "1. \"Climate change is a hoax invented by scientists.\"\n",
    "2. \"The Great Wall of China is visible from space.\"\n",
    "\n",
    "Example 2\n",
    "Input:\n",
    "The Pacific Ocean is the largest ocean on Earth. Drinking bleach can cure illnesses.\n",
    "\n",
    "Output:\n",
    "1. \"Drinking bleach can cure illnesses.\"\n",
    "\n",
    "Example 3\n",
    "Input:\n",
    "\n",
    "Output:\n",
    "No erroneous claims found.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def claim_detection_assistant(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Analyze free text, segment it into statements, and flag each for erroneous claim.\n",
    "\n",
    "    Args:\n",
    "        query: Free-form text containing one or more statements\n",
    "\n",
    "    Returns:\n",
    "        The potentially erroneous claims.\n",
    "    \"\"\"\n",
    "    formatted_query = f\"Please identify erroneous or misleading claims with supporting evidence and context: {query}\"\n",
    "\n",
    "    try:\n",
    "        research_agent = Agent(\n",
    "            model=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "            system_prompt=CLAIM_DETECTION_ASSISTANT_SYSTEM_PROMPT,\n",
    "        )\n",
    "\n",
    "        agent_response = research_agent(formatted_query)\n",
    "        text_response = str(agent_response)\n",
    "\n",
    "        if len(text_response) > 0:\n",
    "            return text_response\n",
    "\n",
    "        return \"I apologize, but I couldn't identify any erroneous claims. Please check if your query is clearly stated or try rephrasing it.\"\n",
    "    except Exception as e:\n",
    "        # Return specific error message for math processing\n",
    "        return f\"Error identifying erroneous claims: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write Supervisor Agent for Fact Checking to Frontend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../src/frontend/fact_check_supervisor.py\n",
    "\n",
    "import base64\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import assistant modules from the same directory\n",
    "from mcp import StdioServerParameters, stdio_client\n",
    "from strands import Agent, tool\n",
    "from strands.tools.mcp import MCPClient\n",
    "\n",
    "# Get the absolute path to the frontend directory (where this script is located)\n",
    "frontend_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Add the frontend directory to the Python path\n",
    "if frontend_dir not in sys.path:\n",
    "    sys.path.append(frontend_dir)\n",
    "\n",
    "from claim_detection_assistant import claim_detection_assistant\n",
    "from math_assistant import math_assistant\n",
    "from research_assistant import research_assistant\n",
    "\n",
    "SUPERVISOR_SYSTEM_PROMPT = \"\"\"\n",
    "You are a sophisticated misinformation detection orchestrator that coordinates specialized agents for comprehensive content analysis and fact-checking. Your primary mission is to detect, analyze, and verify information for potential misinformation.\n",
    "\n",
    "## Available Specialized Agents\n",
    "\n",
    "You have access to these specialized agents:\n",
    "\n",
    "1. **claim_detection_assistant** - Claim Detection Assistant\n",
    "   - Breaks down input text into separate statements\n",
    "   - Identifies potentially false or misleading claims\n",
    "   - Returns a numbered list of erroneous claims as direct quotations\n",
    "   - Use for: Initial content analysis, statement extraction, identifying suspicious claims\n",
    "\n",
    "2. **research_assistant** - External Fact Checker Assistant\n",
    "   - Performs deep fact-checking with evidence using DuckDuckGo search\n",
    "   - Searches reliable sources and cross-references information\n",
    "   - Provides TRUE/FALSE/PARTIALLY TRUE verdicts with supporting evidence\n",
    "   - Use for: Verifying specific claims, finding authoritative sources, detailed fact-checking\n",
    "\n",
    "3. **math_assistant** - Math Wizard\n",
    "   - Validates mathematical claims and calculations\n",
    "   - Checks numerical accuracy and statistical validity\n",
    "   - Analyzes quantitative statements for errors\n",
    "   - Use for: Mathematical fact-checking, statistical claims, numerical verification\n",
    "\n",
    "## Orchestration Strategy\n",
    "\n",
    "For comprehensive misinformation detection, follow this multi-step approach:\n",
    "\n",
    "### Step 1: Initial Analysis\n",
    "- Use **claim_detection_assistant** to segment content and identify potentially problematic statements\n",
    "- This provides a structured list of all claims that need verification\n",
    "\n",
    "### Step 2: Specialized Verification\n",
    "- For mathematical/statistical claims → Use **math_assistant**\n",
    "- For factual claims requiring evidence → Use **research_assistant**\n",
    "- For complex claims → Coordinate multiple agents as needed\n",
    "\n",
    "### Step 3: Synthesis\n",
    "- Combine results from all agents\n",
    "- Provide concise assessment with evidence\n",
    "- Highlight the most concerning misinformation risks\n",
    "\n",
    "## Trigger Keywords for Misinformation Analysis\n",
    "\n",
    "Always initiate the multi-agent workflow when you detect:\n",
    "- \"fact-check\", \"verify claims\", \"check if true\"\n",
    "- \"misinformation\", \"disinformation\", \"fake news\", \"suspicious content\"\n",
    "- Any request to evaluate content truthfulness\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Always start with claim_detection_assistant** for content segmentation\n",
    "2. **Use research_assistant** for claims requiring external verification\n",
    "3. **Use math_assistant** for any numerical or statistical claims\n",
    "4. **Coordinate multiple agents** for comprehensive analysis\n",
    "5. **Provide clear, evidence-based conclusions**\n",
    "\n",
    "Your goal is to provide concise, accurate misinformation detection by leveraging the specialized capabilities of each agent in a coordinated manner.\n",
    "\"\"\"\n",
    "\n",
    "# --- Langfuse & OTEL Observability Setup ---\n",
    "\n",
    "# Specify the path to your .env file (in the same directory as this script)\n",
    "env_path = os.path.join(frontend_dir, \".env\")\n",
    "\n",
    "# Load the environment variables from the specified file\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Configure langfuse for observability\n",
    "LANGFUSE_AUTH = base64.b64encode(\n",
    "    f\"{os.environ.get('LANGFUSE_PUBLIC_KEY')}:{os.environ.get('LANGFUSE_SECRET_KEY')}\".encode()\n",
    ").decode()\n",
    "\n",
    "# Handle case where LANGFUSE_HOST might be None\n",
    "langfuse_host = os.environ.get(\"LANGFUSE_HOST\")\n",
    "if langfuse_host:\n",
    "    os.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = (\n",
    "        langfuse_host + \"/api/public/otel/v1/traces\"\n",
    "    )\n",
    "else:\n",
    "    logging.warning(\n",
    "        \"LANGFUSE_HOST environment variable not set, skipping OTEL configuration\"\n",
    "    )\n",
    "\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"Authorization=Basic {LANGFUSE_AUTH}\"\n",
    "\n",
    "# Start MCP client\n",
    "stdio_mcp_client = MCPClient(\n",
    "    lambda: stdio_client(\n",
    "        StdioServerParameters(\n",
    "            command=\"uvx\",\n",
    "            args=[\"duckduckgo-mcp-server\"],\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "## Create Supervisor Agent for Fact Checking\n",
    "@tool\n",
    "def fact_check_supervisor(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Process queries through the multi-agent fact-checking system.\n",
    "\n",
    "    Args:\n",
    "        query: The text to analyze for factual accuracy\n",
    "\n",
    "    Returns:\n",
    "        str: A comprehensive fact-check assessment\n",
    "    \"\"\"\n",
    "    # Use MCP client context manager to ensure session is active\n",
    "    with stdio_mcp_client:\n",
    "        try:\n",
    "            # Combine custom tools with MCP tools\n",
    "            all_tools = [\n",
    "                math_assistant,\n",
    "                claim_detection_assistant,\n",
    "                research_assistant,\n",
    "            ]\n",
    "\n",
    "            # Create the supervisor agent within MCP context\n",
    "            supervisor = Agent(\n",
    "                model=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "                system_prompt=SUPERVISOR_SYSTEM_PROMPT,\n",
    "                tools=all_tools,\n",
    "            )\n",
    "\n",
    "            # Process the query within the same MCP context\n",
    "            return supervisor(\n",
    "                f\"Provide a comprehensive fact-check assessment for this text: {query}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing query with MCP tools: {str(e)}\")\n",
    "\n",
    "            # Fallback to supervisor without MCP tools\n",
    "            supervisor = Agent(\n",
    "                model=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "                system_prompt=SUPERVISOR_SYSTEM_PROMPT,\n",
    "                tools=[\n",
    "                    math_assistant,\n",
    "                    claim_detection_assistant,\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            return supervisor(\n",
    "                f\"Provide a comprehensive fact-check assessment for this text: {query}\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test the Complete Multi-Agent System\n",
    "\n",
    "Now let's test the complete multi-agent system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Now import using absolute import\n",
    "from Fact_Check_Assistant.src.frontend.fact_check_supervisor import (\n",
    "    fact_check_supervisor,\n",
    ")\n",
    "\n",
    "print(\"\\n\\nInvoking fact-checking supervisor agent...\\n\\n\")\n",
    "\n",
    "response = fact_check_supervisor(\n",
    "    \"The Earth is flat and this has been proven by multiple scientific studies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.message[\"content\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Access the Application in Development Mode\n",
    "\n",
    "To run the Fact Check Assistant application locally in development mode:\n",
    "\n",
    "1. **Open a new terminal window** in Jupyter Hub\n",
    "\n",
    "2. **Navigate to the frontend directory:**\n",
    "\n",
    "```bash\n",
    "cd sample-building-agentic-ai-applications-on-aws-fact-check-assistant/Fact_Check_Assistant/src/frontend\n",
    "```\n",
    "   \n",
    "Start the Streamlit application:\n",
    "\n",
    "```bash\n",
    "python -m streamlit run app.py\n",
    "```\n",
    "\n",
    "Access the application in your browser at:\n",
    "\n",
    "```https://<session>.studio.<region>.sagemaker.aws/jupyterlab/default/proxy/8501/\n",
    "```\n",
    "\n",
    "> ℹ️ Information: Replace <session> and <region> with the actual values from your current browser URL. You can find these values in your SageMaker Studio address bar.\n",
    "\n",
    "The application will be available on port 8501 and accessible through the SageMaker Studio proxy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] 9. Deploy the CDK Stack for the Fact Checking Application\n",
    "\n",
    "> Information: ℹ️ You will need to execute steps 9 and 10 outside of SageMaker Studio. The environment you use must meet the flow **prerequisites**.\n",
    "\n",
    "This AWS CDK stack sets up a containerized application that to run a streamlit application that interacts with our fact checking agent created above. It automatically builds and deploys the service using AWS Fargate (a serverless container platform) and exposes it through a load-balanced endpoint.\n",
    "\n",
    "> ⚠️ Warning: The **Application Load Balancer (ALB)** created by this stack is **publicly accessible** over the internet. This means: **Anyone with the ALB DNS name can send requests** to your service (assuming security group and app-level controls allow it). While this is necessary for public-facing applications, it can pose a **security risk** if not properly protected.\n",
    "\n",
    "Prerequisites\n",
    "\n",
    "- [AWS CLI](https://aws.amazon.com/cli/) installed and configured\n",
    "- [Node.js](https://nodejs.org/) (v18.x or later)\n",
    "- Python 3.11 or later\n",
    "  - Either:\n",
    "    - [Podman](https://podman.io/) installed and running\n",
    "    - (or) [Docker](https://www.docker.com/) installed and running\n",
    "    - Ensure podman or docker daemon is running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ../src/infra/deploy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional] 10. Access the application\n",
    "\n",
    "The application can be opened in a web browser by navigating to the URL provided in the output of the CDK deployment script. This URL is the endpoint for the load-balanced application. You can also access the application by using the ALB DNS name provided in the output of the CDK deployment script.\n",
    "\n",
    "> ⚠️ Warning: The **Application Load Balancer (ALB)** created by this stack is **publicly accessible** over the internet. This means: **Anyone with the ALB DNS name can send requests** to your service (assuming security group and app-level controls allow it). While this is necessary for public-facing applications, it can pose a **security risk** if not properly protected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Get the service URL from CDK output using AWS CLI\n",
    "result = subprocess.run(\n",
    "    [\n",
    "        \"aws\",\n",
    "        \"cloudformation\",\n",
    "        \"describe-stacks\",\n",
    "        \"--stack-name\",\n",
    "        \"FactCheckAssistantStack\",\n",
    "        \"--query\",\n",
    "        \"Stacks[0].Outputs[?OutputKey=='ApplicationURL'].OutputValue\",\n",
    "        \"--output\",\n",
    "        \"text\",\n",
    "    ],\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "SERVICE_URL = result.stdout.strip()\n",
    "print(f\"Service URL: {SERVICE_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
